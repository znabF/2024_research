{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9983d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edbc666",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe7bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397ef56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e4ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c19732",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da237548",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a173be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wavio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02ecc7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.11/site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.15.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (0.36.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.15.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.29.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-macos==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e9711b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg in /opt/anaconda3/lib/python3.11/site-packages (1.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "797205a8-d287-41da-902a-6efa294b99e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.16.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.3.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.62.1)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Using cached tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow)\n",
      "  Using cached keras-3.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.0)\n",
      "Using cached tensorflow-2.16.1-cp311-cp311-macosx_12_0_arm64.whl (227.0 MB)\n",
      "Using cached keras-3.2.0-py3-none-any.whl (1.1 MB)\n",
      "Using cached ml_dtypes-0.3.2-cp311-cp311-macosx_10_9_universal2.whl (389 kB)\n",
      "Using cached tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "Installing collected packages: ml-dtypes, tensorboard, keras, tensorflow\n",
      "Successfully installed keras-3.2.0 ml-dtypes-0.3.2 tensorboard-2.16.2 tensorflow-2.16.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c4c06de-83e4-4c21-aae6-f6aa14bcc7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: keras in /opt/anaconda3/lib/python3.11/site-packages (3.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.11/site-packages (from keras) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.11/site-packages (from keras) (0.0.7)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.11/site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.11/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b5fd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0                            i didnt feel humiliated      0\n",
      "1  i can go from feeling so hopeless to so damned...      0\n",
      "2   im grabbing a minute to post i feel greedy wrong      3\n",
      "3  i am ever feeling nostalgic about the fireplac...      2\n",
      "4                               i am feeling grouchy      3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:89: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[47m \u001b[30m I'm angry.\n",
      "1/1 - 0s - 273ms/step\n",
      "\u001b[47m \u001b[30m Predicted Emotion: Anger\n",
      "\u001b[41m \u001b[30m \n",
      "It may be surprising but humor is a great technique to talk yourself out of your anger. Anger is healthy but if you are reaching to a\n",
      "point where it is damaging your relationship the advice would be to solve this matter of your emotions.\n",
      "Anger portrays incorrect images of you in front of individuals in a converstation. A joke to get you laugh would\n",
      "set you up for success in managing your anger.\n",
      "\n",
      "Here is a video full of jokes to make crack up: https://youtu.be/NMIjkqZFN9o\n",
      " .Do not say anything for 45 seconds as the program will not read it.\n",
      "\u001b[47m \u001b[30m No.\n",
      "1/1 - 0s - 10ms/step\n",
      "\u001b[47m \u001b[30m Predicted Emotion: Fearful\n",
      "\u001b[42m \u001b[37m \n",
      "This anxiety can be cured with simplest of things. Having a routine to divert your focus may help you conquer your everday goals without that anxiety\n",
      "being a hurdle. To begin, everyday things like a good night’s sleep, a wholesome meal and a walk are often the best cures for anxiety.\n",
      "Even it could be having supportive people around you and make a tradition to do an activity with them recurrently.\n",
      "\n",
      "Here is a guide on how to make the best routine: \n",
      "https://www.calm.com/blog/daily-routine\n",
      " .Do not say anything for 45 seconds as the program will not read it.\n"
     ]
    }
   ],
   "source": [
    "# all libs for audio/whisper transcription\n",
    "import sounddevice as sd # recording compatibility\n",
    "import wavio as wv # audio file compatibilty\n",
    "import datetime # to ensure it is live recording by keeping track of time\n",
    "import config\n",
    "import os, glob\n",
    "import whisper\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Embedding, Bidirectional, LSTM, AveragePooling1D, BatchNormalization\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np # brings functionality of arrays data structure to python, used a lot in machine learning\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from colorama import  Back, Style, Fore\n",
    "\n",
    "\n",
    "\n",
    "# Assuming your dataset is in CSV format with columns 'text' and 'label'\n",
    "# Adjust the file path accordingly\n",
    "file_path = 'nlpData/training.csv'\n",
    "\n",
    "# Load the dataset using pandas\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Access the 'text' and 'label' columns\n",
    "texts = df['text'].tolist()\n",
    "labels = df['label'].tolist()\n",
    "\n",
    "# generic for all emotions\n",
    "RULER = \"\"\"\n",
    "Let's utilize the RULER method to manage this tough emotion you are experiencing. \n",
    "First sense it and be mindful of it let it be there. Stop and pause and think of your best self. \n",
    "To get to your best self think of ways that help enhance your mood right now.\n",
    "\"\"\"\n",
    "\n",
    "# sad feedbacks\n",
    "sad_1 = \"\"\"\n",
    "Pause.  Your words may impact others wrongly so please take a pause. \n",
    "Is what your saying really going to help? \n",
    "Make a list of pros and cons if you further persist with this attitude. \n",
    "If there are a lot of cons then please control yourself before impacting your relationships. \n",
    "Try engaging with your senses through ice packs, scents, etc. \n",
    "or walk away from the situation (if possible) and perform a joyful activity. \n",
    "Remember not all content has to be tried out, these are just ideas from your personal emotion regulation therapist.\n",
    "\"\"\"\n",
    "\n",
    "sad_2 = \"\"\"\n",
    "When others may hear what you say they may feel hurt. \n",
    "If it is commenting on someone, keep it to yourself so your relationships do not get damaged. \n",
    "If you are thinking of ending a relationship do it in a fulfilling manner where the other individual \n",
    "does not feel offended by speaking assertively and using “I” statements. \n",
    "Remember not all content has to be tried out, these are just ideas from your personal emotion regulation therapist.\n",
    "\"\"\"\n",
    "\n",
    "sad_3 = \"\"\"\n",
    "If you are in a moderate place, ask yourself, “why am I sad?”. \n",
    "If not, then work on distractions to distract that emotion and come back to that question of why. \n",
    "Accepting and being mindful of the situation you are encountering may help you come up with solutions for a better outcome. \n",
    "Remember not all content has to be tried out, these are just ideas from your personal emotion regulation therapist. \n",
    "Remember (think of your own positive affirmation as you know yourself the best)\n",
    "\"\"\"\n",
    "\n",
    "sad_4 = \"\"\"\n",
    "Sometimes it is better to reach out to people to share your pain with them. \n",
    "Start by using “I” statements and speaking assertively to make it easy to contact with others around you for support. \n",
    "Try positive mantras in your head example of a positive mantra:\n",
    "\"I am doing my best everyday\" \n",
    "The senses are also a great distraction to take your mind off of what you are sad and engage in something soothing for you.\n",
    "\"\"\"\n",
    "\n",
    "sad_5 = \"\"\"\n",
    "Consider doing opposite action. This is when you want to do the opposite of what your thoughts are impulsing you to do. \n",
    "But first, check if your emotion fits well to the scenario you are facing.Trust me, this will work easy peasy. \n",
    "Think about the pros and cons if you do what you think of doing right now? Will it serve you long term?\n",
    "If it does not, do not do it.\n",
    "Another resource is to change your body temperature to distract from something else.\n",
    "Take a break from the situation and go grab an ice pack or whatever temperature/texture is soothing for you. \n",
    "Think of others around you so you can refrain yourself from anything aggressive and come to wise or rational mind.\n",
    "Remember not all content has to be tried out, these are just ideas from your personal emotion regulation therapist.\n",
    "\"\"\"\n",
    "\n",
    "sad_6 = \"\"\"\n",
    "Engage in pleasant activities to further enhance your mood or be mindful of the emotion that is occurring right now. \n",
    "Remember not all content has to be tried out, these are just ideas from your personal emotion regulation therapist.\n",
    "\"\"\"\n",
    "\n",
    "sad_7 = \"\"\"\n",
    "Guided Meditation/self talk:\n",
    "Now hear yourself saying: Each day, in every way, I get better and better. \n",
    "In order to make change I challenge myself. \n",
    "When I have a negative thought, I acknowledge that I feel this way and then I release it. When another negative thought arises, I catch it quickly and I say with confidence, I acknowledge that part of me feels this way, but this thought does not help me right now. \n",
    "Each day, in every way I get better and better. \n",
    "Every single day, I become more aware of all the good things going on in my community, and in the world around me. \n",
    "When I feel that darkness is surrounding me, I know that the way to see light is to take 3 deep breaths, \n",
    "relaxing my mind and body by doing so. \n",
    "In order to make great change, I challenge my thoughts. \n",
    "\"\"\"\n",
    "\n",
    "sad_8 = \"\"\"\n",
    "These are best for when in grief/distress.\n",
    "1. Stay in touch with others around you so they know how you are feeling.\n",
    "2. Exercise is a great way to alleviate yourself from distress but please do so if you have the medical capability. Try participating in healthy activities that you find enjoyable.\n",
    "3. Keeping up with good nutriiton will enable the nutrients to better help you shift into wise mind (where emotion mind and rational mind are balanced). It is okay to not be achieving your wise mind on your first try.\n",
    "4. Routines always help as you know what will happen next rather having a new emotion about an uncertain event. Example of a routine can be found here: https://www.calm.com/blog/daily-routine\n",
    "5. Enjoy and be gracious for all the resources this world has bestowed upon you, it will help you think of the brighter side of the picture.\n",
    "\"\"\"\n",
    "\n",
    "# list to randomize these (all of them are helpful)\n",
    "sad_feedbacks = [sad_1, sad_2, sad_3, sad_4, sad_5, sad_6, sad_7, sad_8, RULER]\n",
    "\n",
    "\n",
    "# fearful feedbacks\n",
    "fearful_1 = \"\"\"\n",
    "Anxiety can be overwhelming. But emohelp.ai is here to help! Our system has noticed you are feeling anxious. \n",
    "You should first ground yourself and sit with the anxiety. When sitting with anxiety, start noticing what is around you. \n",
    "5 things you can see, 4 things you can touch, 3 things you can hear, 2 things you can smell, and 1 thing you can taste. \n",
    "Now to contact the senses rather than noticing them, self-soothe yourself with the senses that appeal to you in a calming manner. \n",
    "That could be taking a warm bath, rubbing your hands through velvet, etc. Be aware of not engaging in sensory activities \n",
    "that disturb you! Distraction is also key to overcoming anxiety. Distractions help as \n",
    "they shift the mind from unwanted thoughts to the thoughts your wise mind desires to be fed by. \n",
    "Examples of distractions can be, watching TV, talking to your loved ones, walking your pet (if you have one), \n",
    "doing community service, etc. If it is a social situation, think of this experience as an exposure get \n",
    "yourself exposed to those fears to cure your anxiety in the long term. Use “I” statements to speak up.\n",
    "Remember not all content has to be tried out, these are just ideas from your personal emotion regulation therapist.\n",
    "\"\"\"\n",
    "\n",
    "fearful_2 = \"\"\"\n",
    "If it was something that was actually distressing, speaking of rational terms, try using pleasing imagery playing in your mind \n",
    "to lift off the disgusting thoughts. However, if it is not a reasonably disgusting moment, exposure may be advised. \n",
    "To start off with the exposure of your fear, your values and goals can be used as a motivator to complete the exposure for doing \n",
    "what is “distressing”. Remember not all content has to be tried out, these are just ideas from \n",
    "your personal emotion regulation therapist.\n",
    "\n",
    "Here is a video of a pleasant imagery guided meditation:\n",
    "https://youtu.be/AbckuluEdM0\n",
    "\"\"\"\n",
    "\n",
    "fearful_3 = \"\"\"\n",
    "Take a step back and realize what’s going on. Reframe the anxious thoughts you are having. \n",
    "Anxious thoughts can be identified by the thoughts that start bringing up fear in your body through sensations \n",
    "or just a feeling you know. Communicate your needs if the anxiety is coming from a third party source. \n",
    "To advocate for your needs it could mean redirecting people around you that are causing your anxiety. \n",
    "It may be anxious to do so but remember the outcome of advocating for your needs–it will help you overcome your anxiety. \n",
    "Try telling the person who is with you what you are scared of by using “I” statements. \n",
    "Remember not all content has to be tried out, these are just ideas from your personal emotion regulation therapist.\n",
    "\n",
    "To have a powerful presence in your converstation of communication your needs, here is a video to help:\n",
    "https://youtu.be/mq8YmWaybeE?t=166\n",
    "\"\"\"\n",
    "\n",
    "fearful_4 = \"\"\"\n",
    "Envision your favorite place in the world where you feel best. \n",
    "Imagine your loved one sitting next to you watching this moment arise.\n",
    "Now, you fly with your loved one to a place of minimal worry.\n",
    "\"\"\"\n",
    "\n",
    "fearful_5 = \"\"\"\n",
    "Guided Meditation:\n",
    "Get comfortable. You can lie on your back in bed or on the floor with a pillow under your head and knees.\n",
    "Or you can sit in a chair with your shoulders, head, and neck supported against the back of the chair.\n",
    "Breathe in through your nose. Let your belly fill with air.\n",
    "Breathe out through your nose.\n",
    "Place one hand on your belly. Place the other hand on your chest.\n",
    "As you breathe in, feel your belly rise. As you breathe out, feel your belly lower.\n",
    "The hand on your belly should move more than the one that's on your chest.\n",
    "Take three more full, deep breaths. Breathe fully into your belly as it rises and falls with your breath.\n",
    "Whenever I am presented with feelings of stress, \n",
    "I know my breath is there to soothe me and guide me into relaxation.\n",
    "\"\"\"\n",
    "\n",
    "fearful_6 = \"\"\"\n",
    "Live by the facts. What is evidence of the fear you hold? Will this matter in 1, 2, 5, 25 years? \n",
    "Answering these questions \n",
    "may make you realize whether or not this fear is rational. Having that knowledge, it is hoped for your success in \n",
    "overcoming this troubling experience. For example, you go into a social gathering and you get the wrong perception \n",
    "of people so you are scared for your life that they may embarrass you. Think about the evidence supporting your fear \n",
    "and evidence against it. As this is most likely an irrational fear, you may find that there is more evidence against it. \n",
    "Since you are finding more of the unsupportive evidence, there is a possibility that it would be easier for you to realize\n",
    "that people embarrasing you lasts short-term.\n",
    "\"\"\"\n",
    "\n",
    "fearful_7 = \"\"\"\n",
    "This anxiety can be cured with simplest of things. Having a routine to divert your focus may help you conquer your everday goals without that anxiety\n",
    "being a hurdle. To begin, everyday things like a good night’s sleep, a wholesome meal and a walk are often the best cures for anxiety.\n",
    "Even it could be having supportive people around you and make a tradition to do an activity with them recurrently.\n",
    "\n",
    "Here is a guide on how to make the best routine: \n",
    "https://www.calm.com/blog/daily-routine\n",
    "\"\"\"\n",
    "\n",
    "fearful_8 = \"\"\"\n",
    "Try to make rewards for everything you accomplish to increase your self-compassion and motivation to face your anxiety or fear. If you know\n",
    "that for example you might get ice cream after being in a social situation that may help you to engage in a converstation.\n",
    "\"\"\"\n",
    "\n",
    "fearful_feedbacks = [fearful_1, fearful_2, fearful_3, fearful_4, fearful_5, fearful_6, fearful_7, fearful_8, RULER]\n",
    "\n",
    "angry_1 = \"\"\"\"\n",
    "Take a step back and realize what’s going on. Reframe the anxious thoughts you are having. \n",
    "angry thoughts can be identified by the thoughts that start bringing up angry heat in your body through sensations \n",
    "or just a feeling you know. Communicate your needs if the anger is coming from someone else. \n",
    "To advocate for your needs it could mean redirecting people around you that are causing your anger. \n",
    "It may be anxious to do so but remember the outcome of advocating for your needs–it will help you overcome your anxiety. \n",
    "Try telling the person who is with you who triggered you by using “I” statements. \n",
    "Remember not all content has to be tried out, these are just ideas from your personal emotion regulation therapist.\n",
    "\"\"\"\n",
    "\n",
    "angry_2 = \"\"\"\n",
    "Drink water, sit down, think of the positives of the aspect.\n",
    "Get yourself out of emotion mind and into wise mind by thinking if the \n",
    "emotion really fits the facts.\n",
    "\"\"\"\n",
    "\n",
    "angry_3 = \"\"\"\n",
    "Consider doing opposite action. This is when you want to do the opposite of what your thoughts are impulsing you to do. \n",
    "But first, check if your emotion fits well to the scenario you are facing.Trust me, this will work easy peasy. \n",
    "Think about the pros and cons if you do what you think of doing right now? Will it serve you long term?\n",
    "If it does not, do not do it.\n",
    "Another resource is to change your body temperature to distract from something else.\n",
    "Take a break from the situation and go grab an ice pack or whatever temperature/texture is soothing for you. \n",
    "Think about others around you, how they would feel hurt by your actions triggered by your anger. \n",
    "Think of them so you can refrain yourself from anything aggressive and come to wise or rational mind.\n",
    "Remember not all content has to be tried out, these are just ideas from your personal emotion regulation therapist.\n",
    "\"\"\"\n",
    "\n",
    "angry_4 = \"\"\"\n",
    "When others may hear what you say they may feel hurt. \n",
    "If it is commenting on someone, keep it to yourself so your relationships do not get damaged. \n",
    "If you are thinking of ending a relationship do it in a fulfilling manner where the other individual \n",
    "does not feel offended by speaking assertively and using “I” statements. \n",
    "Remember not all content has to be tried out, these are just ideas from your personal emotion regulation therapist.\n",
    "\n",
    "Try this video on anger management: \n",
    "https://youtu.be/hxZS50WhhBI\n",
    "\"\"\"\n",
    "\n",
    "angry_5 = \"\"\"\n",
    "It’s time to take a break…. and relax…. to deal with anger in a healthy, productive way.\n",
    "\n",
    "Anger is a normal and natural emotion, and there is nothing wrong with having feelings – you are human, after all. \n",
    "You have the power to decide how to deal with this emotion you are experiencing.\n",
    "\n",
    "Anger management does not mean holding anger in. \n",
    "It does not mean that you will never feel angry. \n",
    "Anger management is managing the behavioral responses that can arise when you are feeling angry.\n",
    "\n",
    "All you really need to do right now is take a few moments just to relax, for you, to help you feel relaxed and calm. It feels good to relax. \n",
    "After this short relaxation session is over, you can proceed with your day, and react in a way that you choose…. relaxing for a moment now will help you to react calmly, \n",
    "rather than acting out of emotion.\n",
    "\n",
    "It’s okay to be angry. Just allow yourself to feel however it is you are feeling right now, noticing this feeling, but not reacting just yet. \n",
    "All you’re doing is observing. \n",
    "Emotions are neither right nor wrong… they just are.\n",
    "\n",
    "Take a deep breath in. \n",
    "Hold for a moment, and now breathe out.\n",
    "\n",
    "Breathe in… hold that tension…. and now breathe out…. feeling the tension release with your breath.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "angry_6 = \"\"\"\n",
    "It may be surprising but humor is a great technique to talk yourself out of your anger. Anger is healthy but if you are reaching to a\n",
    "point where it is damaging your relationship the advice would be to solve this matter of your emotions.\n",
    "Anger portrays incorrect images of you in front of individuals in a converstation. A joke to get you laugh would\n",
    "set you up for success in managing your anger.\n",
    "\n",
    "Here is a video full of jokes to make crack up: https://youtu.be/NMIjkqZFN9o\n",
    "\"\"\"\n",
    "\n",
    "angry_7 = \"\"\"\n",
    "If the anger seems to be on the scale of 9-10 try to find yourself to a private room because screaming may help your temper \n",
    "to cool down as anger would be boiling inside of you. If screaming is not your jam than singing may be (no pun intended). \n",
    "Channeling those feelings into a song may help the anger be released. \n",
    "\n",
    "Once you are rested, check out this video for alternatives on what you can do next time if you are angry that is \n",
    "appropriate in a social situation:\n",
    "https://youtu.be/BsVq5R_F6RA\n",
    "\"\"\"\n",
    "\n",
    "angry_8 = \"\"\"\n",
    "If do not have the guts to share your anger with a human being but know that sharing it to somewhere may help, maybe journaling is the\n",
    "better alternative. Journaling has no rules, just jot your feelings down and let your hand, pencil, and your emotion mind guide \n",
    "(in this case you can listen to emotion mind only on paper). If writing is not for you, draw out your emotional state. Drawing\n",
    "one's emotional state can be triggering so perhaps a change towards articulating pleasant scenery may better help.\n",
    "\n",
    "Here is a therapeutic art activity to manage your anger:\n",
    "https://youtu.be/Ptu2ca2Ezp0?t=163\n",
    "\"\"\"\n",
    "\n",
    "angry_feedbacks = [angry_2, angry_2, angry_3, angry_4, angry_5, angry_6, angry_7, angry_8, RULER]\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# nlp model\n",
    "# intiating the model with Sequential(), Sequential() enables us to create a sequence of layers\n",
    "model = Sequential()\n",
    "\n",
    "# embedding enables the model to categorize already what textual data goes into which class and analyzes further with the following layers\n",
    "# # makes a multidimensional plane where each vector will have slope based on sum, the direction of slope will determine the direction of which class dimension it goes more towards\n",
    "# first param is the # of words there are to learn\n",
    "# second param tells model that our output dimension is 16, each word is represented as a 16 dimensional array (substantial amount of info)\n",
    "# third param tells model that the input size is 50\n",
    "model.add(Embedding(10000, 16, input_shape=(50,)))\n",
    "\n",
    "# lstm layer, bidirectional input is being able to compared in any direction (left and right) regarding the context of the sentence as lstm looks at full word with the help of rnn\n",
    "# LSTM allows us to look further into the context of the sentnece as it is different than a recurrent neural network since it uses cell states to keep track of data over time periods\n",
    "# returning sequences so the next layer of LSTM will know where to continue (stacking LSTM layers)\n",
    "model.add(Bidirectional(LSTM(20, return_sequences=True)))\n",
    "\n",
    "# another lstm layer\n",
    "model.add(Bidirectional(LSTM(20)))\n",
    "\n",
    "# deeply connected, dense layer to make final analyzations ~ output layer\n",
    "model.add(Dense(6, activation=\"softmax\"))\n",
    "\n",
    "model.load_weights(\"nlp_model_weights.h5\")\n",
    "\n",
    "freq = 44100 # 44100 audio samples per second (utilizing sampling method to capture analog data)\n",
    "duration = 5 # 5 seconds for each frame of audio\n",
    "\n",
    "# recordings directory as a list\n",
    "# * means all of the names of the files shall be joined together as one list using os.path.join\n",
    "recordings_dir = os.path.join('recordings', '*')\n",
    "\n",
    "# loading whisper model, small is the type of model (parameters vary for each model) \n",
    "asr_model = whisper.load_model(\"base\")\n",
    "\n",
    "# which audio files have been transcribed\n",
    "transcribed = []\n",
    "TRANSCRIPT_FILE = \"transcript.txt\"\n",
    "\n",
    "\n",
    "while True:\n",
    "    # time right now\n",
    "    ts = datetime.datetime.now()\n",
    "\n",
    "    # time right now is the name of the file by putting the time in string format using format codes\n",
    "    filename = ts.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # start recording and the settings are the given parameters\n",
    "    # for each second there are 44100 frames therefore mutliplying it by 5 seconds (the duration) gives us a complete audio recording\n",
    "    recording = sd.rec(int(duration * freq), samplerate=freq, channels=1)\n",
    "\n",
    "    # giving the audio recording sometime\n",
    "    sd.wait()\n",
    "\n",
    "    # operating systems can not read \":\" in file names\n",
    "    filename = filename.replace(':', '_')\n",
    "\n",
    "    # writing audio to the file we declared the name abiove\n",
    "    # sampwidth = 2 means 4 possible amplitude values (vocab for how high or low the audio is)\n",
    "    wv.write(f\"recordings/{filename}.wav\", recording, freq, sampwidth=2)\n",
    "\n",
    "    \n",
    "\n",
    "    # getting all the names of the files from recent to oldest\n",
    "    # iglob searches for specific files that have a similar pattern in their name (matches our situation) it searches then sorts it (the rule above)\n",
    "    files = sorted(glob.iglob(recordings_dir), key=os.path.getctime, reverse=True)\n",
    "    if len(files) < 1:\n",
    "        continue\n",
    "\n",
    "\n",
    "    # first is the recent one as it was sorted previously (sorted list is files list)\n",
    "    latest_recording = files[0]\n",
    "\n",
    "#     latest_recording_filename = latest_recording.split('/')[1]\n",
    "#     print(files[0])\n",
    "    # checking if the path of the latest file exists and if it is not in the list of transcribed audio\n",
    "    if os.path.exists(latest_recording) and not latest_recording in transcribed:\n",
    "        # loading audio of latest recording\n",
    "        audio = whisper.load_audio(latest_recording)\n",
    "\n",
    "        # padding the audio (adding more) or trimming the audio to meet is required length of 220500 samples\n",
    "        audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "        # visualizes sound waves in a different way and send it to the device the asr model is predicting on \n",
    "        # (helps the asr model out specifically for this type of problem)\n",
    "        mel = whisper.log_mel_spectrogram(audio).to(asr_model.device)\n",
    "\n",
    "        # specific instructions on how the model should behave when outputting its prediction\n",
    "        # english language only and no fp16 (no fast transcription, take time)\n",
    "        options = whisper.DecodingOptions(language= 'en', fp16=False)\n",
    "\n",
    "        # transcribing using model, the distinct looking soundwaves and the format in which it should be outputted\n",
    "        result = whisper.decode(asr_model, mel, options)\n",
    "\n",
    "        # if there is less probability of no speech going on, then we want to do something\n",
    "        if result.no_speech_prob < 0.5:\n",
    "            # print the transcription in the console\n",
    "            print(Back.WHITE, Fore.BLACK, result.text)\n",
    "            \n",
    "            if result.text:\n",
    "\n",
    "                sequences = tokenizer.texts_to_sequences([result.text])\n",
    "                padded = pad_sequences(sequences, truncating=\"post\", padding=\"post\", maxlen=50)\n",
    "                \n",
    "#                 print(\"Sequences:\", sequences)\n",
    "#                 print(\"Padded Sequences:\", padded)\n",
    "#                 print(\"Model Input Shape:\", padded.shape)\n",
    "                \n",
    "                predictions = model.predict(padded, verbose = 2)\n",
    "#                 print(\"Predictions:\", predictions)\n",
    "\n",
    "                # if there is some content in the prediciton list\n",
    "                if predictions.any():\n",
    "                    # dict with every key,value pair of emotion labels helps output the emotion visually\n",
    "                    emotion_mapping = {0: \"Fearful\", 1: \"Sadness\", 2: \"Love\", 3: \"Anger\", 4: \"Fear\", 5: \"Surprise\"}\n",
    "                    # maximum prediction\n",
    "                    predicted_index = np.argmax(predictions)\n",
    "                    \n",
    "                    # retrieve correct emotion based on current index\n",
    "                    predicted_emotion = emotion_mapping.get(predicted_index, \"Unknown\")\n",
    "                    \n",
    "                    # Print the predicted emotion\n",
    "                    print(Back.WHITE, Fore.BLACK, \"Predicted Emotion:\", predicted_emotion)\n",
    "                    \n",
    "                    if predicted_index == 0:\n",
    "                        # shuffle the feedback list to randomize\n",
    "                        shuffled_fearful = sorted(fearful_feedbacks, key=lambda x: random.random())\n",
    "                        \n",
    "                        # get the first element of the shuffled list (will be different for each iteration)\n",
    "                        random_fearful_feedback = shuffled_fearful[0]\n",
    "                        print(Back.GREEN, Fore.WHITE, random_fearful_feedback, \".Do not say anything for 45 seconds as the program will not read it.\")\n",
    "                        time.sleep(20)\n",
    "                    elif predicted_index == 1:\n",
    "                        # shuffle the feedback list to randomize\n",
    "                        shuffled_sad = sorted(sad_feedbacks, key=lambda x: random.random())\n",
    "                        \n",
    "                        # get the first element of the shuffled list (will be different for each iteration)                        \n",
    "                        random_sad_feedback = shuffled_sad[0]\n",
    "                        print(Back.BLUE, Fore.BLACK, random_sad_feedback, \".Do not say anything for 45 seconds as the program will not read it.\")\n",
    "                    elif predicted_index == 3:\n",
    "                        shuffled_angry = sorted(angry_feedbacks, key=lambda x: random.random())\n",
    "                        # get the first element of the shuffled list (will be different for each iteration)                        \n",
    "                        random_angry_feedback = shuffled_angry[0]\n",
    "                        print(Back.RED, Fore.BLACK, random_angry_feedback, \".Do not say anything for 45 seconds as the program will not read it.\")\n",
    "\n",
    "                    \n",
    "#                     print(\"Predicted Index:\", predicted_index)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    print(\"Warning: Predictions are empty.\")\n",
    "\n",
    "            else:\n",
    "                print(\"Warning: Result.text is empty.\")\n",
    "\n",
    "\n",
    "\n",
    "#             if np.argmax(predictions) == 0:\n",
    "#                 print(\"Sadness\")\n",
    "#             elif np.argmax(predictions) == 1:\n",
    "#                 print(\"Joy\")\n",
    "#             elif np.argmax(predictions) == 2:\n",
    "#                 print(\"Love\")\n",
    "#             elif np.argmax(predictions) == 3:\n",
    "#                 print(\"Anger\")\n",
    "#             elif np.argmax(predictions) == 4:\n",
    "#                 print(\"Fear\")\n",
    "#             elif np.argmax(predictions) == 5:\n",
    "#                 print(\"Surprise\")\n",
    "\n",
    "            # writing down all transcriptions into a file using the config library, 'a' stands for appending to a file\n",
    "            # append text to transcript file\n",
    "            with open(TRANSCRIPT_FILE, 'a') as f:\n",
    "                f.write(result.text)\n",
    "        # save list of transcribed recordings so that we don't transcribe the same one again\n",
    "        transcribed.append(latest_recording)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d401df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9049d9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27cf070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
